# RAG Q&A for Toronto Rent & Insurance

This project is a simple **Retrieval-Augmented Generation (RAG)** pipeline using LangChain. It lets you ask questions about Toronto rent and insurance laws, with answers based on a local set of PDF documents.

Everything runs **locally on your machine** â€” no cloud APIs required.

---

## ğŸ“¦ Requirements

1. **Python 3.9+** (check with `python --version`).
2. Install required packages:

```bash
pip install -r requirements.txt
```

Recommended packages in `requirements.txt`:
- `langchain`
- `langchain-community`
- `langchain-chroma`
- `langchain-huggingface`
- `chromadb`
- `pypdf`
- `pygpt4all`

*(You may add more depending on your chosen local LLM integration.)*

3. **PDFs**: Place your source documents (Toronto rent & insurance PDFs) in the `data/` folder.

---

## â–¶ï¸ Running the Pipeline

Once requirements are installed:

```bash
python rag-pipeline.py
```

This will:
1. Load and split the PDFs.
2. Embed the text chunks.
3. Store them in a local vector database (Chroma).
4. Use GPT4All (or another local LLM) to answer your questions.

Example interaction:
```text
Question: What is rent control in Toronto?
Answer: Rent control limits the amount a landlord can increase rent annually... (etc)
```

---

## âš™ï¸ Notes
- On Windows, Ollama is not supported. Instead, this setup uses **GPT4All** for local LLM inference.
- For better performance, use small quantized models (e.g. `mistral-7b-instruct.Q4_0.gguf` or `tinyllama`).
- You can swap out the embedding model (`all-MiniLM-L6-v2`) if you want stronger embeddings.

---

## ğŸ“– Project Structure
```
project/
â”‚â”€â”€ data/                  # Store your PDFs here
â”‚â”€â”€ main.py                # The main RAG pipeline
â”‚â”€â”€ requirements.txt       # Python dependencies
â”‚â”€â”€ README.md              # This file
```

---

## âœ… Done!
You now have a **local, private RAG system** for Toronto rent and insurance questions.

Ask away ğŸš€

